## Software Carpentry - Accelerating Scientific Discovery Through the Effective Use of Technology

### Background

Software Carpentry is scientists teaching scientists to use computing and the
web more effectively in their research. The approach has proven effective:
learners become more productive, confident in their ability to tackle new
challenges, and gain awareness of what is possible. The primary deliverable of
Software Carpentry is a two-day workshops taught by trained volunteer
instructors. Instructors are themselves scientists and programmers who volunteer
their time to develop a stronger community of scientific collaborators. The
Software Carpentry Foundation curates and enhances lesson material in the areas
of The UNIX Shell, version control (Git and Mercurial), programming (Python, R,
Matlab) and data management with databases (SQL).

It is commonplace to observe that computers are as important to modern science
as test tubes and whiteboards. What is pointed out less often is how poorly
scientists use them. From high school onward, scientists are expected to
calibrate their equipment and take careful notes when doing experiments. When
those same scientists use computers for simulations and data analysis, however,
they have very different standards: many do not keep track of software and
parameters accurately enough to be able to reproduce their results, and have no
idea how reliable their software is.

To date, scientists have not worried about these issues because there has been
no incentive for them to do so. Journal or conference reviewers rarely ask how
(or whether) code was tested, and grant reviewers rarely ask whether how much of
the time spent writing software was well spent.

As the pace of discovery accelerates, however, there is increasing pressure for
scientists to build things right and quickly. A wealth of empirical software
engineering research over the past 30 years has demonstrated that the best-in
fact, the only-way to improve quality and productivity is to improve the way in
which software is built. As in manufacturing and medicine, investments repay
themselves several times over because mistakes are more expensive to fix than to
prevent. This realization, at the heart of modern software development
processes, has only been adopted by a minority of scientists.

Science that Works Like the Web: We believe knowing how to code — how to create
content and work on the web — is a core literacy akin to reading or mathematics.
But more than that, we view the web as a 21st century tool, mindset, and force
transforming the nature of professional practice. Working not just on, but like
the web, can accelerate scientific research: data sets become live streams
rather than static files; small ideas grow to become collaborative frameworks;
and researchers gain access to thousands of participants willing to report bird
sightings, analyze old ships' logs, or classify galaxies. Science pioneered open
collaboration and the gift economy, but the web has perfected it. Software
Carpentry was built to re-establish this generative interplay.

Too much emphasis on calculation. Number crunching is also only one part of how
scientists use computers today. Managing data and sharing ideas with colleagues
are already key to effective practice, and becoming more so every day. Too much
emphasis on "big iron". Scientific computing is often identified with
high-performance computing, which skews discussion and training toward the
concerns of a small (but vocal) minority.


### A Five-Point Approach

To turn scientists from passive consumers of software into empowered users and
makers, a successful approach must:

* Target graduate students. Their time is more flexible than that of
undergraduates, but they are still focused on learning. They are often
face-to-face with the challenge of making computers and the web work for them,
instead of the other way around.
* Provide peer- and institutionally-recognized rewards to encourage students to
 prioritize acquiring and passing on these skills.
* Solve immediate problems. Scientists always have pressing deadlines, so any
training must be seen by them to solve problems that they realize they have.
* Use face-to-face instruction as a complement to online learning. A 2010 report
from the US Department of Education found that combining the two produced better
results than either on its own, which is consistent with our experience.
* Engage scientists in a larger learning community, so that they will pass their
skills on to an ever-larger circle of colleagues.

## Examples and Studies

Teaching Scientists to Code: Several studies (see bibliography) of how
scientists use computers and the web, including the largest by Dr. Wilson in
2008-09, have found that most scientists learn what they know about these
subjects through osmosis and word of mouth. Most training meant to address this
issue does not target scientists' specific needs, places too much emphasis on
programming and number crunching, and/or jumps to advanced topics before
scientists have mastered the basics. Software Carpentry is the most significant
effort to date to address the issue. Since its inception in 1997, the program
has taught several thousand researchers the concepts, skills, and tools they
need to get more done in less time and with less pain.

## Leadership

### Steering Committee

Steering committee members serve for a term of one-year. The current steering
committee is comprised of: Matt Davis (USA), Adina Howe (USA), Katy Huff (USA),
Karin Lagessen (Norway), Jason Williams (USA), Raniere Silva (Brazil) and
Alexsandra Pawlik (United Kingdom).


* Roles of the steering committee:
http://software-carpentry.org/scf/committee-roles.html
* Governance bylaws can be found here:
http://software-carpentry.org/scf/governance.html

### Instructors
There are over 125 badged instructors at last count

### Founder
Dr. Greg Wilson: Greg is the founder of Software Carpentry. A 25-year veteran of
the software industry, Greg was co-winner of the Jolt Award for Best General
Technical Book in 2008 and received ComputerWorld Canada's 'IT Educator of the
Year' award in 2010. He started Software Carpentry as a training course at Los
Alamos National Laboratory in 1998. Greg holds a PhD in Computer Science from
the University of Edinburgh.

## Workshops

The workshop host covers the costs of the event (instructors will still not be
paid for their time, but all travel costs will be covered by hosts). The primary
activity of Software Carpentry Foundation staff is to coordinate and match
instructors with institutions working to run Software Carpentry workshops.

## Membership

Institutional Membership Boilerplate can be found at:
http://software-carpentry.org/scf/membership.html


## References
* Jeffrey C. Carver, Richard P. Kendall, Susan E. Squires, and Douglass E. Post:
"Software Development Environments for Scientific and Engineering Software: A
Series of Case Studies." 29th International Conference on Software Engineering,
2007.
* Jo Erskine Hannay, Hans Petter Langtangen, Carolyn MacLeod, Dietmar Pfahl,
Janice Singer, and Greg Wilson: "How Do Scientists Develop and Use Scientific
Software?" Second International Workshop on Software Engineering for
Computational Science and Engineering, 2009.
* Prakash Prabhu, Thomas B. Jablin, Arun Raman, Yun Zhang, Jialu Huang, Hanjun
Kim, Nick P. Johnson, Feng Liu, Soumyadeep Ghosh, Stephen Beard, Taewook Oh,
Matthew Zoufaly, David Walker, and David I. August: "A Survey of the Practice of
Computational Science." 24th ACM/IEEE Conference on High Performance Computing,
Networking, Storage and Analysis, 2011.
* James Howison and James D. Herbsleb: "Scientific Software: Production and
Collaboration." Computer Support for Cooperative Work, 2011.
* Judith Segal: "When Software Engineers Met Research Scientists: A Case Study."
Empirical Software Engineering, 10(4), 2005. 
